{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AssignmentSecond.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Vt9CYn9UuB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas.plotting import table\n",
        "from nltk.tokenize import word_tokenize\n",
        "import seaborn as sns\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "#from wordcloud import WordCloud\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.util import ngrams\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "pd.set_option('max_colwidth',400)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ff82NMGQVWiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('https://raw.githubusercontent.com/cacoderquan/Sentiment-Analysis-on-the-Rotten-Tomatoes-movie-review-dataset/master/train.tsv', sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwhb2z6LbHYx",
        "colab_type": "code",
        "outputId": "83a10f66-de3b-4d90-f4a8-5b10854793ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "train.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage that what is good for the goose</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0         1  ...          1\n",
              "1         2  ...          2\n",
              "2         3  ...          2\n",
              "3         4  ...          2\n",
              "4         5  ...          2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2i3795OkbR42",
        "colab_type": "code",
        "outputId": "1ad98e12-6520-40aa-ac70-b67f039595f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "s=train.tail()\n",
        "df = pd.DataFrame(data=s)\n",
        "fig,ax = plt.subplots(figsize=(10.3,1.2)) \n",
        "ax.xaxis.set_visible(False)  \n",
        "ax.yaxis.set_visible(False)  \n",
        "ax.set_frame_on(False)\n",
        "tab = table(ax, df, loc='upper left')  \n",
        "tab.auto_set_font_size(False)\n",
        "tab.set_fontsize(10)\n",
        "plt.savefig('tail.png')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnoAAABXCAYAAACTB+jNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQgghHNT/B/rJxQTn/UZKAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 741.6x86.4 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jarT_qcLpSdo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fullSentences = []\n",
        "curSentence = 0\n",
        "for i in range(train.shape[0]):\n",
        "  if train['SentenceId'][i]> curSentence:\n",
        "    fullSentences.append((train['Phrase'][i], train['Sentiment'][i]))\n",
        "    curSentence = curSentence +1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPtxpEDXpkr5",
        "colab_type": "code",
        "outputId": "12eb9409-0f8d-43cc-f7a0-4d138d6f8333",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "fullSentDf = pd.DataFrame(fullSentences,columns=['Phrase', 'Sentiment'])\n",
        "fullSentDf.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This quiet , introspective and entertaining independent is worth seeking .</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Even fans of Ismail Merchant 's work , I suspect , would have a hard time sitting through this one .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A positively thrilling combination of ethnography and all the intrigue , betrayal , deceit and murder of a Shakespearean tragedy or a juicy soap opera .</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Aggressive self-glorification and a manipulative whitewash .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                         Phrase  Sentiment\n",
              "0  A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .          1\n",
              "1                                                                                                                    This quiet , introspective and entertaining independent is worth seeking .          4\n",
              "2                                                                                          Even fans of Ismail Merchant 's work , I suspect , would have a hard time sitting through this one .          1\n",
              "3                                      A positively thrilling combination of ethnography and all the intrigue , betrayal , deceit and murder of a Shakespearean tragedy or a juicy soap opera .          3\n",
              "4                                                                                                                                  Aggressive self-glorification and a manipulative whitewash .          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-ka4JqYpm-E",
        "colab_type": "code",
        "outputId": "691332b5-e4df-44f3-88b4-d27c482fda9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "train['Sentiment'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    79582\n",
              "3    32927\n",
              "1    27273\n",
              "4     9206\n",
              "0     7072\n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00GIsAo7VaVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFr5eqt5VdiI",
        "colab_type": "code",
        "outputId": "e0c5a6d5-0af5-4dd6-fa2a-7b9383d68047",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        }
      },
      "source": [
        "train.loc[train.SentenceId == 2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>64</td>\n",
              "      <td>2</td>\n",
              "      <td>This quiet , introspective and entertaining independent is worth seeking .</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>65</td>\n",
              "      <td>2</td>\n",
              "      <td>This quiet , introspective and entertaining independent</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>66</td>\n",
              "      <td>2</td>\n",
              "      <td>This</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>67</td>\n",
              "      <td>2</td>\n",
              "      <td>quiet , introspective and entertaining independent</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>68</td>\n",
              "      <td>2</td>\n",
              "      <td>quiet , introspective and entertaining</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>69</td>\n",
              "      <td>2</td>\n",
              "      <td>quiet</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>70</td>\n",
              "      <td>2</td>\n",
              "      <td>, introspective and entertaining</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>71</td>\n",
              "      <td>2</td>\n",
              "      <td>introspective and entertaining</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>72</td>\n",
              "      <td>2</td>\n",
              "      <td>introspective and</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>73</td>\n",
              "      <td>2</td>\n",
              "      <td>introspective</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>74</td>\n",
              "      <td>2</td>\n",
              "      <td>and</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>75</td>\n",
              "      <td>2</td>\n",
              "      <td>entertaining</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>76</td>\n",
              "      <td>2</td>\n",
              "      <td>independent</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>77</td>\n",
              "      <td>2</td>\n",
              "      <td>is worth seeking .</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>78</td>\n",
              "      <td>2</td>\n",
              "      <td>is worth seeking</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>79</td>\n",
              "      <td>2</td>\n",
              "      <td>is worth</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>80</td>\n",
              "      <td>2</td>\n",
              "      <td>worth</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>81</td>\n",
              "      <td>2</td>\n",
              "      <td>seeking</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    PhraseId  ...  Sentiment\n",
              "63        64  ...          4\n",
              "64        65  ...          3\n",
              "65        66  ...          2\n",
              "66        67  ...          4\n",
              "67        68  ...          3\n",
              "68        69  ...          2\n",
              "69        70  ...          3\n",
              "70        71  ...          3\n",
              "71        72  ...          3\n",
              "72        73  ...          2\n",
              "73        74  ...          2\n",
              "74        75  ...          4\n",
              "75        76  ...          2\n",
              "76        77  ...          3\n",
              "77        78  ...          4\n",
              "78        79  ...          2\n",
              "79        80  ...          2\n",
              "80        81  ...          2\n",
              "\n",
              "[18 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cER-iDc1Vj2c",
        "colab_type": "code",
        "outputId": "f8cf7128-e67a-4a3e-9575-c5d99dc4b94e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "train['Sentiment'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    79582\n",
              "3    32927\n",
              "1    27273\n",
              "4     9206\n",
              "0     7072\n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiNGsybHVmg5",
        "colab_type": "code",
        "outputId": "70e9a495-b8a2-46d7-dd28-a6c0678cefb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import FreqDist\n",
        "from nltk.stem import SnowballStemmer,WordNetLemmatizer\n",
        "stemmer=SnowballStemmer('english')\n",
        "lemma=WordNetLemmatizer()\n",
        "from string import punctuation\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from keras.utils import to_categorical\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtbAfIdYVpFB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_review(review_col):\n",
        "    review_corpus=[]\n",
        "    for i in range(0,len(review_col)):\n",
        "        review=str(review_col[i])\n",
        "        review=re.sub('[^a-zA-Z]',' ',review)\n",
        "        \n",
        "        review=[lemma.lemmatize(w) for w in word_tokenize(str(review).lower())]\n",
        "        review=' '.join(review)\n",
        "        review_corpus.append(review)\n",
        "    return review_corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKOIIyFJVrvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['clean_review']=clean_review(train.Phrase.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-QEVZu7Vy9x",
        "colab_type": "code",
        "outputId": "e028e5b9-7c40-45d1-a341-0a0f24235e61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>clean_review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .</td>\n",
              "      <td>1</td>\n",
              "      <td>a series of escapade demonstrating the adage that what is good for the goose is also good for the gander some of which occasionally amuses but none of which amount to much of a story</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage that what is good for the goose</td>\n",
              "      <td>2</td>\n",
              "      <td>a series of escapade demonstrating the adage that what is good for the goose</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "      <td>a series</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "      <td>series</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...                                                                                                                                                                            clean_review\n",
              "0         1  ...  a series of escapade demonstrating the adage that what is good for the goose is also good for the gander some of which occasionally amuses but none of which amount to much of a story\n",
              "1         2  ...                                                                                                            a series of escapade demonstrating the adage that what is good for the goose\n",
              "2         3  ...                                                                                                                                                                                a series\n",
              "3         4  ...                                                                                                                                                                                       a\n",
              "4         5  ...                                                                                                                                                                                  series\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vV6CnT7V6Kr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import resample\n",
        "train_2 = train[train['Sentiment']==2]\n",
        "train_1 = train[train['Sentiment']==1]\n",
        "train_3 = train[train['Sentiment']==3]\n",
        "train_4 = train[train['Sentiment']==4]\n",
        "train_5 = train[train['Sentiment']==0]\n",
        "train_2_sample = resample(train_2,replace=True,n_samples=55000,random_state=123)\n",
        "train_1_sample = resample(train_1,replace=True,n_samples=55000,random_state=123)\n",
        "train_3_sample = resample(train_3,replace=True,n_samples=55000,random_state=123)\n",
        "train_4_sample = resample(train_4,replace=True,n_samples=55000,random_state=123)\n",
        "train_5_sample = resample(train_5,replace=True,n_samples=55000,random_state=123)\n",
        "\n",
        "df_upsampled = pd.concat([train_2_sample, train_1_sample,train_3_sample,train_4_sample,train_5_sample])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFYSnOqaV9VB",
        "colab_type": "code",
        "outputId": "f2d8f3f8-dbbf-491b-e532-b1bb635eeea7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "df_upsampled.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>clean_review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>28496</th>\n",
              "      <td>28497</td>\n",
              "      <td>1318</td>\n",
              "      <td>J. Wilson</td>\n",
              "      <td>2</td>\n",
              "      <td>j wilson</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52906</th>\n",
              "      <td>52907</td>\n",
              "      <td>2622</td>\n",
              "      <td>special-effects</td>\n",
              "      <td>2</td>\n",
              "      <td>special effect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32421</th>\n",
              "      <td>32422</td>\n",
              "      <td>1519</td>\n",
              "      <td>smash</td>\n",
              "      <td>2</td>\n",
              "      <td>smash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119168</th>\n",
              "      <td>119169</td>\n",
              "      <td>6369</td>\n",
              "      <td>minded</td>\n",
              "      <td>2</td>\n",
              "      <td>minded</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122818</th>\n",
              "      <td>122819</td>\n",
              "      <td>6588</td>\n",
              "      <td>elevated by the wholesome twist of a pesky mother interfering during her son 's discovery of his homosexuality</td>\n",
              "      <td>2</td>\n",
              "      <td>elevated by the wholesome twist of a pesky mother interfering during her son s discovery of his homosexuality</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        PhraseId  ...                                                                                                   clean_review\n",
              "28496      28497  ...                                                                                                       j wilson\n",
              "52906      52907  ...                                                                                                 special effect\n",
              "32421      32422  ...                                                                                                          smash\n",
              "119168    119169  ...                                                                                                         minded\n",
              "122818    122819  ...  elevated by the wholesome twist of a pesky mother interfering during her son s discovery of his homosexuality\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3lhbMIVUpNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "df_upsampled,test = train_test_split(df_upsampled, test_size=0.3, random_state=2003)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYFqIoRQV_1i",
        "colab_type": "code",
        "outputId": "a187cd6d-b653-4bba-b549-a82a46d29d7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "test['clean_review']=clean_review(test.Phrase.values)\n",
        "test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>clean_review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>140688</th>\n",
              "      <td>140689</td>\n",
              "      <td>7633</td>\n",
              "      <td>that 's what I liked about it -- the real issues tucked between the silly and crude storyline</td>\n",
              "      <td>3</td>\n",
              "      <td>that s what i liked about it the real issue tucked between the silly and crude storyline</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107668</th>\n",
              "      <td>107669</td>\n",
              "      <td>5690</td>\n",
              "      <td>exalts the Marxian dream of honest working folk ,</td>\n",
              "      <td>3</td>\n",
              "      <td>exalts the marxian dream of honest working folk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3488</th>\n",
              "      <td>3489</td>\n",
              "      <td>129</td>\n",
              "      <td>pay to see it</td>\n",
              "      <td>3</td>\n",
              "      <td>pay to see it</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97267</th>\n",
              "      <td>97268</td>\n",
              "      <td>5084</td>\n",
              "      <td>'s in danger of going wrong</td>\n",
              "      <td>1</td>\n",
              "      <td>s in danger of going wrong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79673</th>\n",
              "      <td>79674</td>\n",
              "      <td>4102</td>\n",
              "      <td>The plot has a number of holes , and</td>\n",
              "      <td>1</td>\n",
              "      <td>the plot ha a number of hole and</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        PhraseId  ...                                                                              clean_review\n",
              "140688    140689  ...  that s what i liked about it the real issue tucked between the silly and crude storyline\n",
              "107668    107669  ...                                           exalts the marxian dream of honest working folk\n",
              "3488        3489  ...                                                                             pay to see it\n",
              "97267      97268  ...                                                                s in danger of going wrong\n",
              "79673      79674  ...                                                          the plot ha a number of hole and\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QObvYssoWDNG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = ' '.join(df_upsampled.loc[df_upsampled.Sentiment == 4, 'Phrase'].values)\n",
        "text_trigrams = [i for i in ngrams(text.split(), 3)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf4WFShyWGNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Counter(text_trigrams).most_common(30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQbR1WqpWIjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = TweetTokenizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ieRuhmDWLfP",
        "colab_type": "code",
        "outputId": "93f5e5bd-2e98-48f4-d0e2-e3fa3272ce98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "vectorizer = TfidfVectorizer(ngram_range=(1, 3), tokenizer=tokenizer.tokenize)\n",
        "#print(vectorizer)\n",
        "full_text = list(df_upsampled['clean_review'].values) + list(test['clean_review'].values)\n",
        "vectorizer.fit(full_text)\n",
        "df_upsampled_vectorized = vectorizer.transform(df_upsampled['clean_review'])\n",
        "#print(df_upsampled_vectorized)\n",
        "test_vectorized = vectorizer.transform(test['clean_review'])\n",
        "test1 = test['clean_review']\n",
        "test2 = test['Sentiment']\n",
        "test2 = to_categorical(test2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpvHosWqWN5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = df_upsampled['Sentiment']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGpKzVp7Wgeg",
        "colab_type": "code",
        "outputId": "8f8c7f9c-a215-4ad3-9f33-f2b835c417d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "\n",
        "X = df_upsampled['clean_review']\n",
        "# test_set = test['clean review']\n",
        "# Y = train['Sentiment']\n",
        "Y = to_categorical(df_upsampled['Sentiment'].values)\n",
        "print(X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "104742                                    might just be the movie you re looking for\n",
            "30509                                                                      enhancing\n",
            "155713                                              set a new benchmark for lameness\n",
            "132750    to see this terrific film with your kid if you do n t have kid borrow some\n",
            "43497                                          from developing any storytelling flow\n",
            "                                             ...                                    \n",
            "121981                                                                  fritter away\n",
            "62455                                                     is certainly easy to watch\n",
            "65061                                                               this day and age\n",
            "136312                                                                   sweet funny\n",
            "19821                                    an edgy thriller that delivers a surprising\n",
            "Name: clean_review, Length: 192500, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCC7LbQcWqbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=123)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80pW38AhWtL8",
        "colab_type": "code",
        "outputId": "eac89d2a-37f4-4036-d2be-dc138edde2ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_val.shape,Y_val.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(154000,) (154000, 5)\n",
            "(38500,) (38500, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joL-2GVGWvY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGwAKUSqWxas",
        "colab_type": "code",
        "outputId": "9bb82a70-3130-4d75-e3ec-4b86223ed746",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "all_words=' '.join(X_train)\n",
        "all_words=word_tokenize(all_words)\n",
        "#print(all_words)\n",
        "dist=FreqDist(all_words)\n",
        "\n",
        "num_unique_word=len(dist)\n",
        "num_unique_word\n",
        "#X_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13644"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UliKfQIKW0Z1",
        "colab_type": "code",
        "outputId": "b99ba1d3-820f-43ad-88c0-8704c940c3dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "r_len=[]\n",
        "for text in X_train:\n",
        "    word=word_tokenize(text)\n",
        "  #  print(text)\n",
        "    l=len(word)\n",
        "    r_len.append(l)\n",
        "    \n",
        "MAX_REVIEW_LEN=np.max(r_len)\n",
        "MAX_REVIEW_LEN"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTulo3kqW32E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features = num_unique_word\n",
        "max_words = MAX_REVIEW_LEN\n",
        "batch_size = 64\n",
        "epochs = 25\n",
        "num_classes=5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9ZEVgzxW61D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, GRU, Embedding\n",
        "from tensorflow.python.keras.optimizers import Adam\n",
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpWQruJ9XBRE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_val = tokenizer.texts_to_sequences(X_val)\n",
        "\n",
        "X_test = tokenizer.texts_to_sequences(test1)\n",
        "# #X_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mujwPEjdXG88",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import sequence,text\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZPHkJfvXNe2",
        "colab_type": "code",
        "outputId": "f00a4186-c075-4df8-d4f3-dc0c677d35c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "from keras.preprocessing import sequence,text\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
        "X_val = sequence.pad_sequences(X_val, maxlen=max_words)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
        "#print(X_train.shape,X_val.shape)\n",
        "X_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,    3, 1465,  742],\n",
              "       [   0,    0,    0, ...,  489,  548, 1608],\n",
              "       [   0,    0,    0, ...,    5,  103,    6],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,  241,   33, 8571],\n",
              "       [   0,    0,    0, ...,    7,  347,  721],\n",
              "       [   0,    0,    0, ...,  439,    7, 2197]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMt0F_sHXNiG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Dense, Embedding, Flatten\n",
        "from keras.layers import SpatialDropout1D\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
        "from keras.models import Sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8P0dqwrXkGc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = Sequential()\n",
        "\n",
        "# Input / Embdedding\n",
        "model2.add(Embedding(max_features, 150, input_length=max_words))\n",
        "\n",
        "# CNN\n",
        "model2.add(SpatialDropout1D(0.2))\n",
        "\n",
        "model2.add(Conv1D(32, kernel_size=3, padding='same', activation='relu'))\n",
        "model2.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "model2.add(Conv1D(32, kernel_size=3, padding='same', activation='relu'))\n",
        "model2.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "model2.add(Conv1D(64, kernel_size=3, padding='same', activation='relu'))\n",
        "model2.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "model2.add(Flatten())\n",
        "\n",
        "model2.add(Dense(15, activation='softmax'))\n",
        "\n",
        "# Output layer\n",
        "\n",
        "model2.add(Dense(5, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TF2BO-bHXmd7",
        "colab_type": "code",
        "outputId": "bccaaef2-a60d-429b-d8d2-94a5c8545bb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        }
      },
      "source": [
        "model2.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "model2.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=epochs, batch_size=batch_size, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 154000 samples, validate on 38500 samples\n",
            "Epoch 1/25\n",
            "154000/154000 [==============================] - 13s 85us/step - loss: 1.6097 - acc: 0.2011 - val_loss: 1.6094 - val_acc: 0.1993\n",
            "Epoch 2/25\n",
            "154000/154000 [==============================] - 13s 83us/step - loss: 1.6094 - acc: 0.2073 - val_loss: 1.6093 - val_acc: 0.1993\n",
            "Epoch 3/25\n",
            "154000/154000 [==============================] - 13s 83us/step - loss: 1.6093 - acc: 0.2076 - val_loss: 1.6092 - val_acc: 0.2098\n",
            "Epoch 4/25\n",
            "154000/154000 [==============================] - 13s 83us/step - loss: 1.6092 - acc: 0.2144 - val_loss: 1.6090 - val_acc: 0.2030\n",
            "Epoch 5/25\n",
            "154000/154000 [==============================] - 13s 83us/step - loss: 1.6090 - acc: 0.2105 - val_loss: 1.6088 - val_acc: 0.2470\n",
            "Epoch 6/25\n",
            "154000/154000 [==============================] - 13s 83us/step - loss: 1.6087 - acc: 0.2314 - val_loss: 1.6084 - val_acc: 0.2798\n",
            "Epoch 7/25\n",
            "154000/154000 [==============================] - 13s 83us/step - loss: 1.6082 - acc: 0.2362 - val_loss: 1.6078 - val_acc: 0.2722\n",
            "Epoch 8/25\n",
            "154000/154000 [==============================] - 13s 82us/step - loss: 1.6072 - acc: 0.2504 - val_loss: 1.6062 - val_acc: 0.2724\n",
            "Epoch 9/25\n",
            "154000/154000 [==============================] - 13s 83us/step - loss: 1.6037 - acc: 0.2734 - val_loss: 1.5970 - val_acc: 0.2805\n",
            "Epoch 10/25\n",
            "154000/154000 [==============================] - 13s 82us/step - loss: 1.5796 - acc: 0.2788 - val_loss: 1.5656 - val_acc: 0.2860\n",
            "Epoch 11/25\n",
            "154000/154000 [==============================] - 13s 82us/step - loss: 1.5607 - acc: 0.2862 - val_loss: 1.5569 - val_acc: 0.2896\n",
            "Epoch 12/25\n",
            "154000/154000 [==============================] - 13s 83us/step - loss: 1.5554 - acc: 0.2858 - val_loss: 1.5541 - val_acc: 0.2894\n",
            "Epoch 13/25\n",
            "154000/154000 [==============================] - 13s 82us/step - loss: 1.5530 - acc: 0.2859 - val_loss: 1.5513 - val_acc: 0.2882\n",
            "Epoch 14/25\n",
            "154000/154000 [==============================] - 13s 83us/step - loss: 1.5511 - acc: 0.2869 - val_loss: 1.5493 - val_acc: 0.2915\n",
            "Epoch 15/25\n",
            "154000/154000 [==============================] - 13s 81us/step - loss: 1.5487 - acc: 0.2888 - val_loss: 1.5470 - val_acc: 0.2928\n",
            "Epoch 16/25\n",
            "154000/154000 [==============================] - 13s 82us/step - loss: 1.5458 - acc: 0.2931 - val_loss: 1.5433 - val_acc: 0.2947\n",
            "Epoch 17/25\n",
            "154000/154000 [==============================] - 13s 81us/step - loss: 1.5419 - acc: 0.2967 - val_loss: 1.5380 - val_acc: 0.2998\n",
            "Epoch 18/25\n",
            "154000/154000 [==============================] - 13s 82us/step - loss: 1.5361 - acc: 0.3000 - val_loss: 1.5425 - val_acc: 0.2956\n",
            "Epoch 19/25\n",
            "154000/154000 [==============================] - 13s 83us/step - loss: 1.5273 - acc: 0.3039 - val_loss: 1.5249 - val_acc: 0.3044\n",
            "Epoch 20/25\n",
            "154000/154000 [==============================] - 13s 81us/step - loss: 1.5118 - acc: 0.3123 - val_loss: 1.5283 - val_acc: 0.2970\n",
            "Epoch 21/25\n",
            "154000/154000 [==============================] - 13s 83us/step - loss: 1.4861 - acc: 0.3257 - val_loss: 1.4671 - val_acc: 0.3363\n",
            "Epoch 22/25\n",
            "154000/154000 [==============================] - 13s 82us/step - loss: 1.4514 - acc: 0.3428 - val_loss: 1.4400 - val_acc: 0.3426\n",
            "Epoch 23/25\n",
            "154000/154000 [==============================] - 13s 84us/step - loss: 1.4157 - acc: 0.3573 - val_loss: 1.3968 - val_acc: 0.3678\n",
            "Epoch 24/25\n",
            "154000/154000 [==============================] - 13s 85us/step - loss: 1.3863 - acc: 0.3689 - val_loss: 1.3787 - val_acc: 0.3686\n",
            "Epoch 25/25\n",
            "154000/154000 [==============================] - 13s 83us/step - loss: 1.3605 - acc: 0.3805 - val_loss: 1.3622 - val_acc: 0.3802\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3a830f39e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-EKB3C7XsR-",
        "colab_type": "code",
        "outputId": "709d7c60-b968-4522-d35f-932ab0ce9790",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "pred2=model2.predict_classes(X_test,verbose=1)\n",
        "pred2=to_categorical(pred2)\n",
        "print(classification_report(test2,pred2))\n",
        "print(\"Accuracy score:\",accuracy_score(test2,pred2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "82500/82500 [==============================] - 4s 43us/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.36      0.83      0.50     16402\n",
            "           1       0.29      0.09      0.14     16544\n",
            "           2       0.52      0.69      0.59     16464\n",
            "           3       0.31      0.16      0.21     16662\n",
            "           4       0.20      0.11      0.14     16428\n",
            "\n",
            "   micro avg       0.38      0.38      0.38     82500\n",
            "   macro avg       0.34      0.38      0.32     82500\n",
            "weighted avg       0.34      0.38      0.32     82500\n",
            " samples avg       0.38      0.38      0.38     82500\n",
            "\n",
            "Accuracy score: 0.37608484848484847\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2eD4EowaLve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2.save(\"1107843_1dconv_regModel2.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}